{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Pipeline from transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fulim/learning/HuggingFace/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999843955039978},\n",
       " {'label': 'NEGATIVE', 'score': 0.9887484312057495}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", device=0) # device=-1 for CPU, device=0 for GPU\n",
    "\n",
    "\n",
    "results = classifier(\n",
    "    [\"I am enjoying learning LLM\", \"I hate study boring theory\"]\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot classification pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Stephen Curry is best 3-point player in the world',\n",
       " 'labels': ['sport', 'basketball', 'education'],\n",
       " 'scores': [0.6700915694236755, 0.31975847482681274, 0.010149880312383175]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",device=0)\n",
    "\n",
    "classifier(\n",
    "    \"Stephen Curry is best 3-point player in the world\",\n",
    "    candidate_labels=[\"basketball\", \"sport\", \"education\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I am learning the trade and I am ready to help other people as much'},\n",
       " {'generated_text': 'I am learning as much as I can from this amazing person and the world'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", device=0)\n",
    "generator(\n",
    "    \"I am learning\",\n",
    "    num_return_sequences=2,\n",
    "    max_length=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I am learning about, and about my time at University, and that are not just my thoughts, but my thoughts.\\n\\nâ€œ(To'},\n",
       " {'generated_text': 'I am learning the language and I just have to get ready to do anything that I can to educate myself and that is what I am doing.\"\\n'},\n",
       " {'generated_text': 'I am learning the importance of this and I look forward to learning how to better do it.\"\\n\\n\\nSo now you can see that the entire'},\n",
       " {'generated_text': \"I am learning something. I've learned this a great deal.\\n\\nThe answer is no. People should care about the importance that they have in\"},\n",
       " {'generated_text': 'I am learning and feeling from the lessons and experiences that will be put on hand over time. In my work here I am learning about a growing economy'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\",device=0)\n",
    "\n",
    "generator(\n",
    "    \"I am learning\",\n",
    "    num_return_sequences=5,\n",
    "    max_length=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'å¦‚ä½•è¿›æ­¥è‡ªå·± ï¼Ÿ æˆ‘ æ˜¯ ä¸€ å å¤§ å­¦ ç”Ÿ ï¼Œ è¿™ ä¸ª å ä¸ƒ å² çš„ å¹´ çºª ï¼Œ ä¸ çŸ¥ é“ æ€ æ · åš æ‰ å¯ ä»¥ å¾— åˆ° ç† æƒ³ çš„ å·¥ ä½œ ä»¥ åŠ èŒ ä¸š é¢† åŸŸ çš„ å‘ å±• ï¼Œ ç”š è‡³ æƒ³ è¿‡ å» æ‰“ å·¥ ï¼Œ ä½† æ˜¯ å¯¹ è¿™ ä¸ª å¹´ é¾„ æˆ‘ æœ‰ å¾ˆ å¤š çš„ è¿· èŒ« å’Œ å½· å¾¨ - - æˆ‘ åœ¨ è¿™ æ · çš„ æƒ… å†µ ä¸‹ ï¼Œ å¦‚ ä½• åš æ‰ èƒ½ æˆ åŠŸ å‘¢ ï¼Ÿ å…¶ å® ï¼Œ è¿™ ä¸ª é—® é¢˜ å¾ˆ å¥½ ï¼Œ ä¸ æ˜¯ ä¸ çŸ¥ é“ ç›® æ ‡ æ˜¯ ä»€ ä¹ˆ ã€‚ é‚£ äº› æœ‰ å¥½ çš„ å·¥ ä½œ çš„ äºº ï¼Œ ä»– ä»¬ ä¼š é€‰ æ‹© æ¯” ä»– ä»¬ æ›´ æœ‰ é’± ï¼Œ æ›´ æœ‰ èµ„ æœ¬ ï¼Œ æœ‰ æ—¶ å°± æ›´ å–œ æ¬¢ å­¦ ä¹  ï¼Œ æ¯” å¦‚ ï¼Œ ä»– ä»¬ å–œ æ¬¢ åš ä¸€ ä»¶ å¾ˆ é…· çš„ äº‹ ï¼Œ å°± è®© ä»– ä»¬ æ¥ è§¦ åˆ° æ›´ å¤š çš„ å­¦ ä¹  çš„ åœ° æ–¹ ã€‚ åŒ æ · çš„ ä¸€ å¥— ä½“ ç³» ï¼Œ åŒ æ · çš„ ä¸€ ä¸ª äºº åš å¾— æ›´ å¥½ çš„ æ¯” å¦‚ ï¼Œ ä»– ä»¬ ä¼š é€‰ æ‹© ä¸ å·¥ ä½œ æ¥ èµš é’± ï¼Œ æ¯” å¦‚ ï¼Œ ä»– ä»¬ å–œ æ¬¢ åœ¨ å®¶ é‡Œ çš„ ç”µ è„‘ é¢ å‰ ï¼Œ å¯ ä»¥ åš ä¸€ äº› å° ç‚¹ å­ ï¼Œ è¿™ ä¸ª èƒ½ å¤Ÿ è®© ä»– ä»¬ çš„ çŸ¥ è¯† å¾— åˆ° æ›´ å¤š çš„ ç§¯ ç´¯ çš„ åœ° æ–¹ ã€‚ é‚£ ä¹ˆ ï¼Œ è¿™ æ · çš„ äºº çš„ èŒ ä¸š è½¨ è¿¹ å°± æ˜¯ ï¼Œ ä»– ä»¬ æ˜¯ å…ˆ å­¦ ä¹  å† æˆ é•¿ ï¼Œ æˆ æ‰ ã€‚ è¿™ å¯¹ äº ä¸€ ä¸ª æ¯• ä¸š ä¸¤ å¹´ ï¼Œ è¿˜ åœ¨ å‡† å¤‡ é«˜ è€ƒ çš„ äºº æ¥ è¯´ ï¼Œ è¿™ æ˜¯ æœ€ ç» å…¸ çš„'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"uer/gpt2-chinese-cluecorpussmall\", device=0)\n",
    "\n",
    "generator(\n",
    "    \"å¦‚ä½•è¿›æ­¥è‡ªå·±\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask filling pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9847162961959839,\n",
       "  'token': 8320,\n",
       "  'token_str': ' Curry',\n",
       "  'sequence': 'Stephen Curry is the best basketball shooter in the world'},\n",
       " {'score': 0.003812466748058796,\n",
       "  'token': 2250,\n",
       "  'token_str': ' Jackson',\n",
       "  'sequence': 'Stephen Jackson is the best basketball shooter in the world'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", device=0)\n",
    "\n",
    "unmasker(\"Stephen <mask> is the best basketball shooter in the world\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7106127142906189,\n",
       "  'token': 16366,\n",
       "  'token_str': 'Jordan',\n",
       "  'sequence': 'Jordan Jordan is the best basketball player in the world'},\n",
       " {'score': 0.05759501829743385,\n",
       "  'token': 10631,\n",
       "  'token_str': 'Michael',\n",
       "  'sequence': 'Michael Jordan is the best basketball player in the world'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", device=0, model=\"google-bert/bert-base-multilingual-cased\")\n",
    "\n",
    "unmasker(\"[MASK] Jordan is the best basketball player in the world\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/fulim/learning/HuggingFace/.env/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9987391),\n",
       "  'word': 'Fu Lim',\n",
       "  'start': 11,\n",
       "  'end': 17},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': np.float32(0.6181313),\n",
       "  'word': '##AR',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': np.float32(0.50107986),\n",
       "  'word': '##T',\n",
       "  'start': 37,\n",
       "  'end': 38},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.99973094),\n",
       "  'word': 'Kuala Lumpur',\n",
       "  'start': 42,\n",
       "  'end': 54}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True, device=0)\n",
    "\n",
    "ner(\"My name is Fu Lim and I study a TARUMT in Kuala Lumpur from 2020 to 2025.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech tagging pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'PRON',\n",
       "  'score': np.float32(0.99939597),\n",
       "  'index': 1,\n",
       "  'word': 'my',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity': 'NOUN',\n",
       "  'score': np.float32(0.9973929),\n",
       "  'index': 2,\n",
       "  'word': 'name',\n",
       "  'start': 3,\n",
       "  'end': 7},\n",
       " {'entity': 'AUX',\n",
       "  'score': np.float32(0.99475926),\n",
       "  'index': 3,\n",
       "  'word': 'is',\n",
       "  'start': 8,\n",
       "  'end': 10},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9979412),\n",
       "  'index': 4,\n",
       "  'word': 'fu',\n",
       "  'start': 11,\n",
       "  'end': 13},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9987305),\n",
       "  'index': 5,\n",
       "  'word': 'lim',\n",
       "  'start': 14,\n",
       "  'end': 17},\n",
       " {'entity': 'CCONJ',\n",
       "  'score': np.float32(0.9991831),\n",
       "  'index': 6,\n",
       "  'word': 'and',\n",
       "  'start': 18,\n",
       "  'end': 21},\n",
       " {'entity': 'PRON',\n",
       "  'score': np.float32(0.9994572),\n",
       "  'index': 7,\n",
       "  'word': 'i',\n",
       "  'start': 22,\n",
       "  'end': 23},\n",
       " {'entity': 'VERB',\n",
       "  'score': np.float32(0.99835914),\n",
       "  'index': 8,\n",
       "  'word': 'live',\n",
       "  'start': 24,\n",
       "  'end': 28},\n",
       " {'entity': 'ADP',\n",
       "  'score': np.float32(0.9994006),\n",
       "  'index': 9,\n",
       "  'word': 'in',\n",
       "  'start': 29,\n",
       "  'end': 31},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.99853253),\n",
       "  'index': 10,\n",
       "  'word': 'malaysia',\n",
       "  'start': 32,\n",
       "  'end': 40}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\",device=0)\n",
    "\n",
    "pipe(\"My name is Fu Lim and I live in Malaysia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7745416760444641, 'start': 33, 'end': 39, 'answer': 'TARUMT'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", device=0)\n",
    "question_answerer(\n",
    "    question=\"Where do I study?\",\n",
    "    context=\"My name is Fu Lim and I study at TARUMT in Kuala Lumpur\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", device=0)\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation pipeline using a model from the ğŸ¤— Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fulim/learning/HuggingFace/.env/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"I'm learning to generate artificial intelligence.\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-zh-en\", device=0)\n",
    "\n",
    "pipe(\"æˆ‘åœ¨å­¦ä¹ ç”Ÿæˆå¼äººå·¥æ™ºèƒ½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
